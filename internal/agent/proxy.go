package agent

import (
	"fmt"
	"log"
	"net"
	"sync"
	"sync/atomic"
	"time"

	"github.com/natsvr/natsvr/internal/protocol"
)

// LocalProxy manages local port forwarding
type LocalProxy struct {
	client      *Client
	listenPort  int
	targetAgent string
	targetHost  string
	targetPort  int
	protocol    string
	listener    net.Listener
	udpConn     *net.UDPConn
	running     bool
	runMu       sync.Mutex
	tunnelIDGen uint32
}

// NewLocalProxy creates a new local proxy
func NewLocalProxy(client *Client, listenPort int, targetAgent, targetHost string, targetPort int, proto string) *LocalProxy {
	return &LocalProxy{
		client:      client,
		listenPort:  listenPort,
		targetAgent: targetAgent,
		targetHost:  targetHost,
		targetPort:  targetPort,
		protocol:    proto,
	}
}

// Start starts the local proxy
func (p *LocalProxy) Start() error {
	p.runMu.Lock()
	defer p.runMu.Unlock()

	if p.running {
		return fmt.Errorf("proxy already running")
	}

	switch p.protocol {
	case "tcp":
		listener, err := net.Listen("tcp", fmt.Sprintf(":%d", p.listenPort))
		if err != nil {
			return err
		}
		p.listener = listener
		go p.acceptTCP()

	case "udp":
		addr, err := net.ResolveUDPAddr("udp", fmt.Sprintf(":%d", p.listenPort))
		if err != nil {
			return err
		}
		conn, err := net.ListenUDP("udp", addr)
		if err != nil {
			return err
		}
		p.udpConn = conn
		go p.handleUDP()
	}

	p.running = true
	log.Printf("Local proxy started on :%d -> %s:%s:%d", p.listenPort, p.targetAgent, p.targetHost, p.targetPort)

	return nil
}

// Stop stops the local proxy
func (p *LocalProxy) Stop() {
	p.runMu.Lock()
	defer p.runMu.Unlock()

	p.running = false
	if p.listener != nil {
		p.listener.Close()
	}
	if p.udpConn != nil {
		p.udpConn.Close()
	}
}

func (p *LocalProxy) acceptTCP() {
	for {
		p.runMu.Lock()
		running := p.running
		p.runMu.Unlock()

		if !running {
			return
		}

		conn, err := p.listener.Accept()
		if err != nil {
			if p.running {
				log.Printf("Accept error: %v", err)
			}
			continue
		}

		go p.handleTCPConn(conn)
	}
}

func (p *LocalProxy) handleTCPConn(conn net.Conn) {
	defer conn.Close()

	tunnelID := atomic.AddUint32(&p.tunnelIDGen, 1)

	// Request tunnel through agent -> cloud -> target agent
	// This would need to send a special message type that the cloud
	// routes to the target agent

	// For local forwarding, we just connect to the local target
	target, err := net.Dial("tcp", fmt.Sprintf("%s:%d", p.targetHost, p.targetPort))
	if err != nil {
		log.Printf("Failed to connect to target: %v", err)
		return
	}
	defer target.Close()

	log.Printf("Local proxy connection %d established", tunnelID)

	// Bidirectional copy
	done := make(chan struct{}, 2)

	go func() {
		buf := make([]byte, 32768)
		for {
			n, err := conn.Read(buf)
			if err != nil {
				done <- struct{}{}
				return
			}
			if _, err := target.Write(buf[:n]); err != nil {
				done <- struct{}{}
				return
			}
		}
	}()

	go func() {
		buf := make([]byte, 32768)
		for {
			n, err := target.Read(buf)
			if err != nil {
				done <- struct{}{}
				return
			}
			if _, err := conn.Write(buf[:n]); err != nil {
				done <- struct{}{}
				return
			}
		}
	}()

	<-done
	log.Printf("Local proxy connection %d closed", tunnelID)
}

func (p *LocalProxy) handleUDP() {
	buf := make([]byte, 65535)
	clients := make(map[string]*net.UDPAddr)

	for {
		p.runMu.Lock()
		running := p.running
		p.runMu.Unlock()

		if !running {
			return
		}

		n, addr, err := p.udpConn.ReadFromUDP(buf)
		if err != nil {
			continue
		}

		clients[addr.String()] = addr

		// Forward to target
		targetAddr, err := net.ResolveUDPAddr("udp", fmt.Sprintf("%s:%d", p.targetHost, p.targetPort))
		if err != nil {
			continue
		}

		targetConn, err := net.DialUDP("udp", nil, targetAddr)
		if err != nil {
			continue
		}

		targetConn.Write(buf[:n])
		targetConn.Close()
	}
}

// RemoteProxy handles remote forwarding (Cloud -> Agent -> Local Service)
type RemoteProxy struct {
	client   *Client
	tunnels  map[uint32]*RemoteTunnelConn
	tunnelMu sync.RWMutex
}

// P2PProxy handles local proxy for agent-to-agent forwarding
type P2PProxy struct {
	client        *Client
	ruleID        string
	listenPort    int
	targetAgentID string
	targetHost    string
	targetPort    int
	protocol      string
	listener      net.Listener
	udpConn       *net.UDPConn
	running       bool
	runMu         sync.Mutex
	tunnelIDGen   uint32
	tunnels       map[uint32]*P2PTunnelConn // Keyed by global tunnel ID
	tunnelsMu     sync.RWMutex
	pendingAcks   map[uint32]chan *protocol.ConnectAckPayload // Keyed by local tunnel ID
	pendingMu     sync.Mutex
	localToGlobal map[uint32]uint32 // local tunnel ID -> global tunnel ID
	localGlobalMu sync.RWMutex
}

// P2PTunnelConn represents a P2P tunnel connection
type P2PTunnelConn struct {
	LocalTunnelID  uint32   // Local tunnel ID (generated by this agent)
	GlobalTunnelID uint32   // Global tunnel ID (assigned by cloud)
	ClientConn     net.Conn
}

// RemoteTunnelConn represents a remote tunnel connection
type RemoteTunnelConn struct {
	TunnelID   uint32
	LocalConn  net.Conn
	TargetHost string
	TargetPort int
}

// NewRemoteProxy creates a new remote proxy
func NewRemoteProxy(client *Client) *RemoteProxy {
	return &RemoteProxy{
		client:  client,
		tunnels: make(map[uint32]*RemoteTunnelConn),
	}
}

// HandleConnect handles a remote connect request
func (p *RemoteProxy) HandleConnect(tunnelID uint32, targetHost string, targetPort int) error {
	addr := fmt.Sprintf("%s:%d", targetHost, targetPort)
	conn, err := net.Dial("tcp", addr)
	if err != nil {
		return err
	}

	tunnel := &RemoteTunnelConn{
		TunnelID:   tunnelID,
		LocalConn:  conn,
		TargetHost: targetHost,
		TargetPort: targetPort,
	}

	p.tunnelMu.Lock()
	p.tunnels[tunnelID] = tunnel
	p.tunnelMu.Unlock()

	// Start reading from local connection
	go p.readFromLocal(tunnel)

	return nil
}

func (p *RemoteProxy) readFromLocal(tunnel *RemoteTunnelConn) {
	defer func() {
		tunnel.LocalConn.Close()
		p.tunnelMu.Lock()
		delete(p.tunnels, tunnel.TunnelID)
		p.tunnelMu.Unlock()

		// Send close message
		msg := protocol.NewCloseMessage(tunnel.TunnelID)
		p.client.sendMessage(msg)
	}()

	buf := make([]byte, 32768)
	for {
		n, err := tunnel.LocalConn.Read(buf)
		if err != nil {
			return
		}

		msg := protocol.NewDataMessage(tunnel.TunnelID, buf[:n])
		if err := p.client.sendMessage(msg); err != nil {
			return
		}
	}
}

// HandleData handles incoming data for a remote tunnel
func (p *RemoteProxy) HandleData(tunnelID uint32, data []byte) error {
	p.tunnelMu.RLock()
	tunnel, exists := p.tunnels[tunnelID]
	p.tunnelMu.RUnlock()

	if !exists {
		return fmt.Errorf("tunnel %d not found", tunnelID)
	}

	_, err := tunnel.LocalConn.Write(data)
	return err
}

// HandleClose handles a tunnel close message
func (p *RemoteProxy) HandleClose(tunnelID uint32) {
	p.tunnelMu.Lock()
	tunnel, exists := p.tunnels[tunnelID]
	if exists {
		tunnel.LocalConn.Close()
		delete(p.tunnels, tunnelID)
	}
	p.tunnelMu.Unlock()
}

// NewP2PProxy creates a new P2P proxy
func NewP2PProxy(client *Client, ruleID string, listenPort int, targetAgentID, targetHost string, targetPort int, proto string) *P2PProxy {
	return &P2PProxy{
		client:        client,
		ruleID:        ruleID,
		listenPort:    listenPort,
		targetAgentID: targetAgentID,
		targetHost:    targetHost,
		targetPort:    targetPort,
		protocol:      proto,
		tunnels:       make(map[uint32]*P2PTunnelConn),
		pendingAcks:   make(map[uint32]chan *protocol.ConnectAckPayload),
		localToGlobal: make(map[uint32]uint32),
	}
}

// Start starts the P2P proxy
func (p *P2PProxy) Start() error {
	p.runMu.Lock()
	defer p.runMu.Unlock()

	if p.running {
		return fmt.Errorf("proxy already running")
	}

	switch p.protocol {
	case "tcp":
		listener, err := net.Listen("tcp", fmt.Sprintf(":%d", p.listenPort))
		if err != nil {
			return err
		}
		p.listener = listener
		go p.acceptTCP()

	case "udp":
		addr, err := net.ResolveUDPAddr("udp", fmt.Sprintf(":%d", p.listenPort))
		if err != nil {
			return err
		}
		conn, err := net.ListenUDP("udp", addr)
		if err != nil {
			return err
		}
		p.udpConn = conn
		go p.handleUDP()
	}

	p.running = true
	log.Printf("P2P proxy started on :%d -> %s:%s:%d", p.listenPort, p.targetAgentID, p.targetHost, p.targetPort)

	return nil
}

// Stop stops the P2P proxy
func (p *P2PProxy) Stop() {
	p.runMu.Lock()
	defer p.runMu.Unlock()

	p.running = false
	if p.listener != nil {
		p.listener.Close()
	}
	if p.udpConn != nil {
		p.udpConn.Close()
	}

	// Close all tunnel connections
	p.tunnelsMu.Lock()
	for _, tunnel := range p.tunnels {
		tunnel.ClientConn.Close()
	}
	p.tunnels = make(map[uint32]*P2PTunnelConn)
	p.tunnelsMu.Unlock()
}

func (p *P2PProxy) acceptTCP() {
	for {
		p.runMu.Lock()
		running := p.running
		p.runMu.Unlock()

		if !running {
			return
		}

		conn, err := p.listener.Accept()
		if err != nil {
			if p.running {
				log.Printf("P2P proxy accept error: %v", err)
			}
			continue
		}

		go p.handleTCPConn(conn)
	}
}

func (p *P2PProxy) handleTCPConn(conn net.Conn) {
	localTunnelID := atomic.AddUint32(&p.tunnelIDGen, 1)
	remoteAddr := conn.RemoteAddr().String()

	log.Printf("P2P proxy: new connection from %s, local tunnel ID: %d", remoteAddr, localTunnelID)

	// Create pending ack channel keyed by local tunnel ID
	ackChan := make(chan *protocol.ConnectAckPayload, 1)
	p.pendingMu.Lock()
	p.pendingAcks[localTunnelID] = ackChan
	p.pendingMu.Unlock()

	defer func() {
		p.pendingMu.Lock()
		delete(p.pendingAcks, localTunnelID)
		p.pendingMu.Unlock()
	}()

	// Send P2P connect request through cloud with local tunnel ID
	log.Printf("P2P proxy: sending connect request to target agent %s for %s:%d",
		p.targetAgentID, p.targetHost, p.targetPort)

	payload := protocol.EncodeP2PConnectPayload(&protocol.P2PConnectPayload{
		SourceAgentID: p.targetAgentID,
		Protocol:      p.protocol,
		TargetHost:    p.targetHost,
		TargetPort:    uint16(p.targetPort),
	})
	msg := protocol.NewMessage(protocol.MsgTypeP2PConnect, localTunnelID, payload)
	if err := p.client.sendMessage(msg); err != nil {
		log.Printf("P2P proxy: failed to send P2P connect: %v", err)
		conn.Close()
		return
	}

	log.Printf("P2P proxy: waiting for connect ack...")

	// Wait for ack
	var ack *protocol.ConnectAckPayload
	select {
	case ack = <-ackChan:
		if !ack.Success {
			log.Printf("P2P proxy: connect failed: %s", ack.Error)
			conn.Close()
			return
		}
		log.Printf("P2P proxy: connect succeeded, global tunnel ID: %d", ack.TunnelID)
	case <-time.After(30 * time.Second):
		log.Printf("P2P proxy: connect timeout (30s)")
		conn.Close()
		return
	}

	// Get global tunnel ID from ack (cloud assigns this)
	globalTunnelID := ack.TunnelID

	// Store local to global mapping
	p.localGlobalMu.Lock()
	p.localToGlobal[localTunnelID] = globalTunnelID
	p.localGlobalMu.Unlock()

	// Register tunnel by global ID
	p.tunnelsMu.Lock()
	p.tunnels[globalTunnelID] = &P2PTunnelConn{
		LocalTunnelID:  localTunnelID,
		GlobalTunnelID: globalTunnelID,
		ClientConn:     conn,
	}
	p.tunnelsMu.Unlock()

	log.Printf("P2P tunnel established: local=%d global=%d", localTunnelID, globalTunnelID)

	defer func() {
		conn.Close()
		p.tunnelsMu.Lock()
		delete(p.tunnels, globalTunnelID)
		p.tunnelsMu.Unlock()

		p.localGlobalMu.Lock()
		delete(p.localToGlobal, localTunnelID)
		p.localGlobalMu.Unlock()

		// Send close message with global tunnel ID
		p.client.sendMessage(protocol.NewCloseMessage(globalTunnelID))
		log.Printf("P2P tunnel closed: local=%d global=%d", localTunnelID, globalTunnelID)
	}()

	// Read from client and send to cloud using global tunnel ID
	log.Printf("P2P tunnel %d: starting data forwarding", globalTunnelID)
	buf := make([]byte, 32768)
	for {
		p.runMu.Lock()
		running := p.running
		p.runMu.Unlock()

		if !running {
			log.Printf("P2P tunnel %d: proxy stopped", globalTunnelID)
			return
		}

		n, err := conn.Read(buf)
		if err != nil {
			log.Printf("P2P tunnel %d: client read error: %v", globalTunnelID, err)
			return
		}

		if n > 0 {
			log.Printf("P2P tunnel %d: sending %d bytes to target", globalTunnelID, n)
			// Send P2P data through cloud with global tunnel ID
			dataMsg := protocol.NewMessage(protocol.MsgTypeP2PData, globalTunnelID, buf[:n])
			if err := p.client.sendMessage(dataMsg); err != nil {
				log.Printf("P2P tunnel %d: send error: %v", globalTunnelID, err)
				return
			}
		}
	}
}

func (p *P2PProxy) handleUDP() {
	// UDP P2P forwarding would be implemented similarly but more complex
	// For now, just log a warning
	log.Printf("UDP P2P forwarding not yet implemented")
}

// HandleConnectAck handles a P2P connect acknowledgment
// tunnelID here is the local tunnel ID (msg.TunnelID from the P2PConnectAck message)
func (p *P2PProxy) HandleConnectAck(localTunnelID uint32, ack *protocol.ConnectAckPayload) {
	p.pendingMu.Lock()
	ch, exists := p.pendingAcks[localTunnelID]
	p.pendingMu.Unlock()

	if exists {
		select {
		case ch <- ack:
		default:
		}
	}
}

// HandleData handles incoming P2P data for a tunnel
// tunnelID here is the global tunnel ID
// Returns true if the data was handled
func (p *P2PProxy) HandleData(globalTunnelID uint32, data []byte) bool {
	p.tunnelsMu.RLock()
	tunnel, exists := p.tunnels[globalTunnelID]
	p.tunnelsMu.RUnlock()

	if !exists {
		return false
	}

	log.Printf("P2P tunnel %d: received %d bytes from target, writing to client", globalTunnelID, len(data))
	_, err := tunnel.ClientConn.Write(data)
	if err != nil {
		log.Printf("P2P tunnel %d: write to client error: %v", globalTunnelID, err)
		tunnel.ClientConn.Close()
	}
	return true
}

